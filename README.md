# Scene Memory Transformer
*My reimplementation of the [SMT module](https://arxiv.org/abs/1903.03878) for RL*

## Sources
- [Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks](https://arxiv.org/abs/1903.03878)
- [Self-Attention: A Better Building Block for Sentiment Analysis Neural
Network Classifiers](https://aclweb.org/anthology/W18-6219)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html) *(blog)*
- [Lilian Weng's implementation](https://github.com/lilianweng/transformer-tensorflow)
- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/01/attention.html) *(blog)*
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) *(blog)*
